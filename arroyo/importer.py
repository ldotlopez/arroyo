from urllib import parse


from ldotcommons import fetchers, utils


import arroyo.exc
from arroyo import cron, extension, models


class Importer:
    """
    API for import.
    """

    def __init__(self, app):
        self.app = app
        self.app.settings.set_validator(
            self._origin_ns_validator,
            ns='origin')

        self._logger = app.logger.getChild('importer')
        app.signals.register('source-added')
        app.signals.register('source-updated')
        app.signals.register('sources-added-batch')
        app.signals.register('sources-updated-batch')

        app.register_extension('import', ImporterCronTask)

    @staticmethod
    def _origin_ns_validator(k, v):
        # Supported keys are:
        #
        # origin.*.backend (str)
        # origin.*.url (str, NoneType)
        # origin.*.iterations (int, NoneType =>1)
        # origin.*.type (str, NoneType)
        # origin.*.language (str, NoneType)

        parts = k.split('.')
        if len(parts) != 3:
            return v

        k = parts[-1]

        msg = "Invalid value '{}' for '{}'. Must be '{}'"

        if k == 'backend':
            if v is None or not isinstance(v, str) or v == '':
                raise TypeError(msg.format(v, k, str))

        if k in ['url', 'language', 'type']:
            if not isinstance(v, (utils.NoneType, str)) or v == '':
                raise TypeError(msg.format(v, k, str))

        if k == 'iterations':
            if v is None:
                v = 1
            elif not isinstance(k, int):
                try:
                    v = int(v)
                except ValueError:
                    v = 1

        return v

    def get_origins(self):
        """Returns a list of configured origins.

        This list is composed by plugin.Origin objects.
        """

        return list(map(
            self.get_origin_for_origin_spec,
            self.get_origins_specs()))

    def get_origins_specs(self):
        """Returns a list of configured origins in a specification form.

        This list is composed by importer.OriginSpec objects which are
        data-only structures. To get some usable object you may want to use
        importer.Importer.get_origins method
        """

        defs = self.app.settings.get_tree('origin', {})
        if not defs:
            msg = "No origins defined"
            self.app.logger.warning(msg)
            return []

        ret = []
        for (name, params) in defs.items():
            try:
                spec = OriginSpec(name, **params)
                ret.append(spec)
            except TypeError:
                msg = "Invalid origin {name}"
                msg = msg.format(name=name)
                self.app.logger.warn(msg)

        return ret

    def get_origins_for_query_spec(self, query_spec):
        """Get autogenerated origins for a selector.QuerySpec object.

        One query can produce zero or more or plugin.Origins from the activated
        origin extensions.

        Returned origins are configured with one iteration.
        """

        impls = self.app.get_implementations('origin')
        if not impls:
            msg = ("There are no origin implementations available or none of "
                   "them is enabled, check your configuration")
            self.app.logger.warning(msg)
            return []

        ret = []
        for (name, impl) in impls.items():
            origin = impl(self.app, query_spec=query_spec)
            ret.append(origin)

        return ret

    def get_origin_for_origin_spec(self, origin_spec):
        backend = origin_spec.get('backend')
        return self.app.get_extension(
            Origin, backend,
            origin_spec=origin_spec)

    def import_origin(self, origin):
        """Core function for importer.Importer.

        1. Iterate over the URLs produced by origin
        2. Fetch URL and parse content
        3. Process content thru origin parser to get models.Source object
        4. Insert or update DB with those models.

        Within this process the 'created' and 'last_seen' fields from
        models.Source are set.

        Some signals are emited:

        - 'source-added'
        - 'source-updated'
        - 'sources-added-batch',
        - 'sources-updated-batch',
        """

        sources = []
        errors = {}

        for url in origin.get_urls():
            msg = "{name} {iteration}/{iterations}: {url}"
            self._logger.debug(msg.format(
                name=origin.PROVIDER_NAME,
                iteration=origin.iteration,
                iterations=origin.iterations,
                url=url))
            errors[url] = None

            try:
                buff = self.app.fetcher.fetch(url)
            except fetchers.FetchError as e:
                msg = 'Unable to retrieve {url}: {msg}'
                msg = msg.format(url=url, msg=e)
                self._logger.warning(msg)
                errors[url] = e
                continue

            try:
                srcs = origin.process(buff)
            except arroyo.exc.ProcessException as e:
                msg = "Unable to process '{url}': {error}"
                msg = msg.format(url=url, error=e)
                self._logger.error(msg)
                errors[url] = e
                continue

            if not srcs:
                msg = "No sources found in '{url}'"
                msg = msg.format(url=url)
                self._logger.warning(msg)
                continue

            msg = "Found {n} source(s) in '{url}'"
            msg = msg.format(n=len(srcs), url=url)
            self._logger.info(msg)

            sources += srcs

        ret = {
            'added-sources': [],
            'updated-sources': [],
            'errors': errors
        }

        now = utils.now_timestamp()

        for src in sources:
            obj, created = self.app.db.get_or_create(models.Source,
                                                     urn=src['urn'])

            # Override obj's properties with src properties
            for key in src:
                # …except for 'created'
                # Some origins report created timestamps from heuristics,
                # variable or fuzzy data that is degraded over time.
                # For these reason we keep the first 'created' data as the most
                # fiable
                if key == 'created' and \
                   obj.created is not None and \
                   obj.created < src['created']:
                    continue

                setattr(obj, key, src[key])

            obj.last_seen = now

            if created:
                self.app.db.session.add(obj)

            signal_name = 'source-added' if created else 'source-updated'
            self.app.signals.send(signal_name, source=obj)

            batch_key = 'added-sources' if created else 'updated-sources'
            ret[batch_key].append(obj)

        self.app.signals.send('sources-added-batch',
                              sources=ret['added-sources'])
        self.app.signals.send('sources-updated-batch',
                              sources=ret['updated-sources'])

        self.app.db.session.commit()

        return ret

    def import_origin_spec(self, origin_spec):
        origin = self.get_origin_for_origin_spec(origin_spec)
        return self.import_origin(origin)

    def import_query_spec(self, query_spec):
        origins = self.get_origins_for_query_spec(query_spec)
        for origin in origins:

            self.import_origin(origin)

    def run(self):
        for origin in self.get_origins():
            self.import_origin(origin)


class OriginSpec(utils.InmutableDict):
    """Support class to store specification of an origin.

    This class only stores information of an origin, it is not the origin.

    Instances of importer.OriginSpec are used to get a configured plugin.Origin
    from importer.Importer
    """
    def __init__(self, name, backend, url=None, iterations=1, type=None,
                 language=None):
        # Check strs
        strs = [('name', name, False),
                ('backend', backend, False),
                ('url', url, True),
                ('type', type, True),
                ('language', language, True)]

        for (nme, var, nullable) in strs:
            if var is None and nullable:
                continue

            if isinstance(var, str) and var != '':
                continue

            msg = "Invalid value '{value}' for '{name}'. It must be a str"
            msg = msg.format(name=nme, value=var)
            raise TypeError(msg)

        # Check ints
        if not isinstance(iterations, int):
            msg = "Invalid value '{value}' for '{name}'. It must be an int"
            msg = msg.format(name='iterations', value=iterations)
            raise TypeError(msg)

        super().__init__(name=name, backend=backend, url=url,
                         iterations=iterations, type=type, language=language)

    def __repr__(self):
        return "<{pkg}.{clsname}: '{name}'>".format(
            pkg=__name__,
            clsname=self.__class__.__name__,
            name=self.get('name', '(null)'))


class Origin(extension.Extension):
    """Extension point for implemented Origin extension.

    Origin extensions are responsible to parse websites or fetch information
    from other services.

    They must override or implement:

    - class attribute BASE_URL: Default URL (or URI) of website. This URL will
        be used if no other is specified
    - class attribute PROVIDER_NAME: Unique (among other ext.Origin
        implementations) identifier
    - method process_buffer: Given a utf8 buffer this function should return a
        list of dicts with found information. Those dicts can containing the
        same fields present in models.Source, only name and uri are mandatory

    They can override:

    - method paginate: Given a URL returns a generator object which yields that
        URL and subsequent URLs
    - method get_query_url: Given a selector.QuerySpec object returns the URL
        containing that search result for the website that ext.Origin
        implements

    This class also contains some helper methods for child classes, check docs
    or code for more information
    """

    def __init__(self, app, origin_spec=None, query_spec=None):
        super(Origin, self).__init__(app)

        if origin_spec and query_spec:
            msg = 'origin_spec and query_spec are mutually exclusive'
            raise ValueError(msg)

        self._iteration = 0

        if origin_spec:
            self._name = origin_spec['name']
            self._url = origin_spec['url'] or self.BASE_URL
            self._iterations = origin_spec['iterations']
            self._overrides = {k: v for (k, v) in {
                'type': origin_spec['type'],
                'language': origin_spec['language'],
            }.items() if v is not None}

        else:
            self._name = 'internal query'
            self._url = self.get_query_url(query_spec)
            self._iterations = 1
            self._overrides = {}

    @property
    def iteration(self):
        return self._iteration

    @property
    def iterations(self):
        return self._iterations

    def get_urls(self):
        if not self._url:
            return

        iterations = max(1, self._iterations)
        g = self.paginate(self._url)
        while self._iteration < iterations:
            self._iteration += 1
            yield next(g)

    def get_query_url(self, query):
        return

    def process(self, buff):
        """
        Get protosources from origin. Integrity of collected data is guaranteed
        """
        now = utils.now_timestamp()

        deprecated_warn = False

        def fix_data(psrc):
            nonlocal deprecated_warn

            if not isinstance(psrc, dict):
                return None

            # Apply overrides
            psrc.update(self._overrides)

            # Trim-down protosrc
            if 'timestamp' in psrc and not deprecated_warn:
                msg = ("Provider {provider} is using deprecated field "
                       "«timestamp»")
                msg = msg.format(provider=self.PROVIDER_NAME)
                self.app.logger.warning(msg)
                deprecated_warn = True

            psrc = {k: psrc.get(k, None) for k in [
                'name', 'uri', 'created', 'size', 'seeds', 'leechers',
                'language', 'type'
            ]}

            # Calculate URN
            try:
                psrc['urn'] = parse.parse_qs(
                    parse.urlparse(psrc['uri']).query)['xt'][-1]
            except (IndexError, KeyError):
                return None

            # Check strings fields
            for k in ['urn', 'name', 'uri']:
                if not isinstance(psrc[k], str):
                    return None

            # Fix and check integer fields
            for k in ['created', 'size', 'seeds', 'leechers']:
                if not isinstance(psrc[k], int):
                    try:
                        psrc[k] = int(psrc[k])
                    except (TypeError, ValueError):
                        psrc[k] = None

            # Fix created
            psrc['created'] = psrc.get('created', None) or now

            psrc['provider'] = self.PROVIDER_NAME

            # All done
            return psrc

        def filter_incomplete(psrc):
            if not isinstance(psrc, dict):
                return False

            needed = ['name', 'uri', 'urn']
            return all((isinstance(psrc.get(x, None), str) for x in needed))

        ret = self.process_buffer(buff)
        ret = map(fix_data, ret)
        ret = filter(filter_incomplete, ret)

        return list(ret)

    def paginate_by_query_param(self, url, key, default=1):
        parsed = parse.urlparse(url)
        parsed_qs = parse.parse_qs(parsed.query)
        try:
            page = int(parsed_qs.pop(key, [str(default)])[0])
        except ValueError:
            page = 1

        while True:
            parsed_qs[key] = str(page)
            yield parse.urlunparse((parsed.scheme, parsed.netloc, parsed.path,
                                    parsed.params,
                                    parse.urlencode(parsed_qs, doseq=True),
                                    parsed.fragment))
            page += 1

    def __repr__(self):
        return "<%s (%s)>" % (
            self.__class__.__name__,
            getattr(self, '_url', '(None)'))


class ImporterCronTask(cron.CronTask):
    NAME = 'importer'
    INTERVAL = '3H'

    def run(self):
        self.app.importer.run()
        super().run()
